# -*- coding: utf-8 -*-
"""movie_data_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NQjOYGGEcgFrZONjrf1D30xTYwMGMIsO

# Phase 2: Data Analyst - Exploration & Visualisation

L'Objectif dans cette phase est d'Analyser les données de MovieLens via le SDK et en déduire des tendances et statistiques clés.
"""

# Importation des librairies nécessaires
import pandas as pd
import plotly.express as px # pip install plotly-express
import matplotlib.pyplot as plt # pip install matplotlib
import seaborn as sns # pip install seaborn
from moviesdk import MovieClient, MovieConfig

import time

"""## Se familiariser avec l'API"""

# Connexion à l'API via le SDK

config = MovieConfig(movie_base_url="https://movielens-api-rmr7.onrender.com")
client = MovieClient(config=config)

# Vérification que l'API est opérationnelle
client.health_check()

"""On explore les données comme le ferait un Data Analyst."""

# Récupération d’un film pour test
movie = client.get_movie(1)
print(f"Titre : {movie.title}")
print(f"Genres : {movie.genres}")

"""Passons à l'Exploration de la table des évaluations (`ratings`)."""

# On récupère une grande portion de la table (à ajuster selon la taille réelle)
ratings_df = client.list_ratings(limit=100, output_format="pandas")
ratings_df.head()

ratings_df.info()

# Statistiques sur les utilisateurs
user_counts = ratings_df['userId'].value_counts().reset_index()
user_counts

"""La méthode `get_analytics()` fournit un moyen **intelligent et efficace** d'estimer la **taille totale** de la table `ratings` sans deviner la limite à l’aveugle. On peut donc :

1. Utiliser `client.get_analytics()` pour récupérer le **nombre total d'évaluations** (`ratings_count`)
2. Utiliser ce total comme `limit` pour appeler `list_ratings`
3. Créer un DataFrame `complete_ratings_df` contenant **toutes** les évaluations
"""

# 1. Récupération des statistiques globales
analytics = client.get_analytics()
print(analytics)

type(analytics)

# Extraction de la valeur directement
total_ratings = analytics.rating_count
print(f"Nombre total d'évaluations : {total_ratings}")

# Conversion vers dict
analytics_dict = analytics.model_dump()
total_ratings = analytics_dict["rating_count"]
print(total_ratings)

"""Si on essaie le code ci-dessous, on obtiendra une erreur 422 et c'est tout à fait mormal."""

# 2. Téléchargement complet de la table ratings
complete_ratings_df = client.list_ratings(
    limit=total_ratings,
    output_format="pandas"
)
complete_ratings_df.shape

"""L'erreur signifie que l'API **refuse de traiter ta requête** parce que le paramètre `limit=100836` est trop élevé pour elle. En général, les APIs REST ont une **limite maximale de résultats** que tu peux demander en une seule fois — souvent autour de 100, 500, voire 1000. Cela permet non seulement de préserver les performances de l'API et d'éviter des surcharges côté serveur, mais aussi d'assurer un contrôle sur les accès aux données. C'est là l'un des grands avantages de la mise en place d'APIs : elles permettent de **partager des données de manière sécurisée** et d’**encadrer l’utilisation des ressources**.

Ces limites peuvent aussi être mises en place pour des raisons **commerciales**, notamment si l'API est utilisée pour vendre ou monétiser des données. En fixant des limites sur le nombre de résultats ou le nombre d'appels, l'entreprise qui fournit l'API peut contrôler l'accès aux données et éviter des abus tout en gérant ses coûts opérationnels.

Cela permet donc de voir les limites de l'API non seulement sous un angle technique et sécuritaire, mais aussi stratégique et commercial.

On cherchera un moyen de récupérer tous les utilisateurs.
"""

user_counts.columns = ['user_id', 'num_ratings']
user_counts

"""Le Data Analyst discute avec le Développeur de l'API et du SDK et comprend que le SDK moviesdk n’expose pas de méthode explicite pour interroger la table users, ni get_user, ni list_users.

A la lecture de la documention de l'API via Swagger, il va essayer l'option de reconstitution des utilisateurs depuis les ratings.
"""

# Liste des user_id uniques
user_ids = ratings_df['userId'].unique()
print(f"Nombre d'utilisateurs uniques : {len(user_ids)}")
print(f"Exemple d'identifiants utilisateurs : {user_ids[:5]}")

"""## Métriques générales sur un échantillon de 100 évaluations"""

# Récupérer un échantillon de 100 évaluations
sample_ratings_df = client.list_ratings(limit=100, output_format="pandas")
sample_ratings_df.head()

# Nombre d'évaluations par film
ratings_per_movie = sample_ratings_df['movieId'].value_counts().rename_axis('movieId').reset_index(name='rating_count')
print("\nÉvaluations par film :")
print(ratings_per_movie.head())

# Nombre d'évaluations par utilisateur
ratings_per_user = sample_ratings_df['userId'].value_counts().rename_axis('userId').reset_index(name='rating_count')
print("\nÉvaluations par utilisateur :")
print(ratings_per_user)

"""On ne peut pas récupérer les 100 836 lignes d’un coup à cause d’une limite côté API, mais on peut tout à fait récupérer les évaluations par lots (batches) puis agréger les résultats : Traitement par lots (*Batch processing*)."""

# 1. Récupérer le total d’évaluations
total_ratings = client.get_analytics().rating_count
batch_size = 500
all_ratings = []

# 2. Boucle sur les batches avec pause
for skip in range(0, total_ratings, batch_size):
    print(f"Téléchargement des lignes {skip} à {skip + batch_size}...")
    batch_df = client.list_ratings(skip=skip, limit=batch_size, output_format="pandas")
    all_ratings.append(batch_df)
    time.sleep(1)  # pause de 0.5 seconde

# 3. Concaténer tous les résultats
complete_ratings_df = pd.concat(all_ratings, ignore_index=True)

# 4. Agrégation : nombre d’évaluations par utilisateur
ratings_per_user = complete_ratings_df['userId'].value_counts().rename_axis('userId').reset_index(name='rating_count')

# 5. Affichage
ratings_per_user

complete_ratings_df.head()

complete_ratings_df.info()

"""Plutôt que de tout stocker en mémoire et concaténer à la fin, tu peux faire le comptage utilisateur par utilisateur dans chaque chunk, puis agréger les résultats intermédiaires pour obtenir le total final."""

# Agréger rating_count par userId, chunk par chunk

# 1. Récupérer le total d’évaluations
total_ratings = client.get_analytics().rating_count
batch_size = 500

# 2. Dictionnaire pour accumuler les totaux par userId
from collections import defaultdict
user_rating_counts = defaultdict(int)

# 3. Parcours des chunks
for skip in range(0, total_ratings, batch_size):
    print(f"Traitement du batch {skip} à {skip + batch_size}...")
    batch_df = client.list_ratings(skip=skip, limit=batch_size, output_format="pandas")

    # Comptage des évaluations par utilisateur dans le batch
    batch_counts = batch_df['userId'].value_counts()

    # Mise à jour du compteur global
    for user_id, count in batch_counts.items():
        user_rating_counts[user_id] += count

    time.sleep(1)

# 4. Conversion en DataFrame finale
ratings_per_user = pd.DataFrame(list(user_rating_counts.items()), columns=["userId", "rating_count"])

# 5. Tri (optionnel)
ratings_per_user = ratings_per_user.sort_values(by="rating_count", ascending=False)

# 6. Affichage
ratings_per_user

"""## Question Business pertinente

**Quels genres de films les utilisateurs taguent le plus positivement (note ≥ 4.0), et quels sont les tags les plus fréquents associés à ces genres ?**

### Pourquoi c’est pertinent ?
- Cela permet de **comprendre les préférences des utilisateurs** non seulement à travers les notes, mais aussi via les **tags qualitatifs** qu’ils ajoutent.
- Un **analyste marketing** ou un **algorithme de recommandation** peut utiliser cette information pour :
  - recommander des films similaires,
  - optimiser la classification des films,
  - mieux comprendre les "moods" ou intentions derrière les notes élevées.

---

### Données nécessaires (via SDK + API) :
- **`ratings`** : pour filtrer sur les évaluations élevées (`rating ≥ 4.0`).
- **`tags`** : pour voir quels tags sont utilisés sur les mêmes `(userId, movieId)`.
- **`movies`** : pour enrichir avec les genres correspondants.

---

### Étapes principales :
1. Lister toutes les **ratings ≥ 4.0** (en batch si nécessaire).
2. Pour chaque `(user_id, movieId)` filtré, essayer de récupérer un **tag** via `client.get_tag(...)` ou en listant tous les tags et croisant.
3. Récupérer les **genres du film** via `client.get_movie(movieId)`.
4. Agréger : **genre ↔️ tag ↔️ fréquence**.
"""

# Étape 1 : Récupérer les évaluations élevées (rating >= 4.0) par lots

chunk_size = 500
skip = 0
all_high_ratings = []

while True:
    chunk = client.list_ratings(
        skip=skip,
        limit=chunk_size,
        min_rating=4.0,
        output_format="pandas"
    )

    if chunk.empty:
        break

    all_high_ratings.append(chunk)
    skip += chunk_size
    time.sleep(1)  # Pause entre appels pour éviter les erreurs 429

# Fusionner tous les chunks
high_ratings_df = pd.concat(all_high_ratings, ignore_index=True)
print(high_ratings_df.shape)
high_ratings_df

# Étape 2 : Identifier les couples (userId, movieId) uniques

user_movie_pairs = high_ratings_df[['userId', 'movieId']].drop_duplicates()
user_movie_pairs

#  Étape 3 : Récupérer les tags correspondants

# Récupération de tous les tags
all_tags = []
skip = 0
chunk_size = 500
while True:
    tag_chunk = client.list_tags(skip=skip, limit=chunk_size, output_format="pandas")
    if tag_chunk.empty:
        break
    all_tags.append(tag_chunk)
    skip += chunk_size
    time.sleep(1)

all_tags_df = pd.concat(all_tags, ignore_index=True)

# Merge avec les high ratings
tagged_high_ratings = pd.merge(user_movie_pairs, all_tags_df, on=["userId", "movieId"])
print(tagged_high_ratings.shape)
tagged_high_ratings

# Étape 4 : Récupérer les genres associés aux movieId

def get_movie_genre(movie_id):
    try:
        movie = client.get_movie(movie_id)
        return movie.genres
    except:
        return ""

# Appliquer uniquement aux movieId uniques qu’on a en tags
unique_movie_ids = tagged_high_ratings['movieId'].unique()

movie_genres = {
    movie_id: get_movie_genre(movie_id)
    for movie_id in unique_movie_ids
}

# Ajoutons la colonne genre
tagged_high_ratings['genres'] = tagged_high_ratings['movieId'].map(movie_genres)
print(tagged_high_ratings.shape)
tagged_high_ratings

# Étape 5 : Agrégation finale : genre ↔ tag ↔ count

# On "explose" les genres s'ils sont séparés par "|"
tagged_high_ratings['genres'] = tagged_high_ratings['genres'].str.split('|')
tagged_exploded = tagged_high_ratings.explode('genres')

tagged_exploded

# Compter les combinaisons Genre / Tag
genre_tag_summary = (
    tagged_exploded
    .groupby(['genres', 'tag'])
    .size()
    .reset_index(name='count')
    .sort_values(by='count', ascending=False)
)

genre_tag_summary

"""Ce tableau `genre_tag_summary` fournit une **analyse croisée entre les genres de films et les tags les plus utilisés** par les utilisateurs qui ont **attribué une note élevée** (`rating >= 4.0`). Voici quelques commentaires et interprétations intéressantes :

---

### **Ce que le tableau montre**
- Chaque ligne représente une combinaison unique de **genre** et de **tag**.
- La colonne `count` indique **le nombre de fois** qu’un certain **tag** a été associé à un film d’un certain **genre**, dans le contexte d’une **note élevée**.
- Exemple :  
  - `Drama` + `In Netflix queue` a été tagué **20 fois** pour des films bien notés de genre `Drama`.
  - `Thriller` + `twist ending` a été tagué **16 fois**, ce qui donne des indices sur ce que les gens aiment dans les thrillers.

---

### **Interprétations business**
1. **Découverte des préférences spectateurs par genre :**
   - Les utilisateurs aiment les **films dramatiques** qu’ils prévoient de regarder plus tard (`In Netflix queue`) — ce tag peut refléter de l'intérêt ou de la recommandation indirecte.
   - Les **Thrillers** avec des `twist endings` ou une ambiance `suspense` sont particulièrement appréciés → à prioriser pour la recommandation.

2. **Utilité pour un moteur de recommandation :**
   - En analysant les tags les plus associés à des films bien notés dans chaque genre, on peut mieux orienter les recommandations personnalisées.
   - Par exemple, recommander des **films “Mystery” avec des twists** à ceux qui aiment les “Thrillers” bien notés avec ce tag.

3. **Insights marketing / catégorisation :**
   - Les plateformes peuvent créer des catégories comme :
     - “**Mystery with a Twist**”
     - “**Atmospheric Dramas**”
     - “**Suspenseful Thrillers**”
   - Ces regroupements peuvent améliorer l’engagement en renforçant la correspondance entre ce que les gens aiment et ce qu’on leur propose.

---

### À noter :
- Ce tableau est basé **uniquement sur les films bien notés**, ce qui biaise volontairement l’analyse pour extraire **ce que les utilisateurs apprécient**.
- Les tags sont **libres**, donc il peut y avoir du bruit (noms d’acteurs, fautes de frappe, etc.).
- Une étape de **nettoyage/normalisation des tags** pourrait encore améliorer l’analyse.

---

On peut aussi explorer les **tags associés aux films mal notés**. On pourrait comparer les deux profils de tags pour voir ce qui plaît ou non dans chaque genre.
"""