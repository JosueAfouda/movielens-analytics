# **Phase 2 : Data Analyst - Exploration et Visualisation**  

![](architecturephase.png)

## Introduction

**Objectif : Explorer et analyser les donn√©es en interrogeant l‚ÄôAPI.**  

üîπ **Analyse Exploratoire des Donn√©es (EDA)** :  
- Utiliser le **SDK Python** pour requ√™ter l‚ÄôAPI et r√©cup√©rer les donn√©es.  
- Identifier les tendances dans les notes des films.  
- √âtudier les genres les plus populaires et les pr√©f√©rences des utilisateurs.  

üîπ **Construction d‚Äôune Data App avec Streamlit** :  
- Cr√©er une **application interactive** qui permet de visualiser les tendances du cin√©ma.  
- Int√©grer des **tableaux dynamiques** et des **graphiques interactifs**.  
- Offrir une **recherche avanc√©e** des films en fonction des notes et des genres.  

**Livrables** :  
- Un notebook d'analyse exploratoire interactif.  
- Une **application web Streamlit** connect√©e √† l‚ÄôAPI qui pr√©sente, de mani√®re interactive, les insights aux parties prenantes.

---

## Pr√©sentation de Jupyter Notebook

**Jupyter Notebook** est un environnement interactif tr√®s populaire dans le monde de la **Data Science**. Il permet d‚Äô√©crire du code Python, de visualiser des graphiques, d‚Äôins√©rer des textes explicatifs (en Markdown), et de documenter une analyse de donn√©es de mani√®re fluide et lisible.

---

### Pourquoi Jupyter Notebook est si populaire ?

üîπ **Interactivit√© totale** : Chaque cellule de code peut √™tre ex√©cut√©e ind√©pendamment, ce qui permet d‚Äôexplorer les donn√©es pas √† pas.

üîπ **Documentation int√©gr√©e** : On peut facilement alterner entre du code Python et des explications en langage naturel (Markdown), ce qui en fait un excellent outil p√©dagogique et professionnel.

üîπ **Visualisation imm√©diate** : Les biblioth√®ques comme `matplotlib`, `seaborn` ou `plotly` s‚Äôint√®grent parfaitement √† Jupyter pour cr√©er des visualisations dynamiques.

üîπ **Support riche** : Int√®gre du HTML, des tableaux interactifs, des widgets, etc. Parfait pour pr√©senter un projet √† un client ou √† une √©quipe.

---

### Un outil central pour le Data Analyst

Durant la phase 2, vous utiliserez Jupyter Notebook pour :

- Charger et explorer les donn√©es extraites via votre SDK (et donc indirectement via l‚ÄôAPI).
- R√©aliser une **analyse exploratoire** compl√®te : tendances, corr√©lations, genres populaires...
- Visualiser les r√©sultats sous forme de **graphiques** compr√©hensibles et exploitables.
- Cr√©er un **notebook professionnel** que vous pourrez int√©grer dans votre portfolio.

---

Parfait, voici une version retravaill√©e de la section **Installation rapide** (renomm√©e en **‚öôÔ∏è Mise en place de l‚Äôenvironnement d‚Äôanalyse**), adapt√©e au contexte de la formation, en pr√©cisant que l‚Äôon travaille avec **VSCode**, un environnement virtuel Python, et un d√©p√¥t GitHub :

---

## Mise en place de l‚Äôenvironnement d‚Äôanalyse

Dans cette formation, nous utilisons **VSCode** comme √©diteur principal et organisons chaque phase dans un r√©pertoire Git d√©di√©. Pour cette phase 2 (*Data Analyst ‚Äì Exploration & Visualisation*), tu vas travailler dans un nouveau projet nomm√© par exemple `movielens-analytics` (tu cr√©es ton propre r√©pertoire GitHub et tu lui donnes le nom que tu veux)

Voici les √©tapes pour bien d√©marrer :

### 1. Cloner le d√©p√¥t GitHub du projet

Si ce n‚Äôest pas encore fait, commence par cloner le d√©p√¥t Git que tu as cr√©√© pour cette phase :

```bash
git clone https://github.com/JosueAfouda/movielens-analytics.git
cd movielens-analytics
```

### 2. Cr√©er et activer un environnement virtuel

Ensuite, configure un environnement Python isol√© pour g√©rer les d√©pendances :

```bash
python3 -m venv .venv
source .venv/bin/activate
```

> Si tu es sur Windows, utilise :  
> `.\.venv\Scripts\activate`

### 3. Ouvrir le projet dans VSCode

```bash
code .
```

Si tu re√ßois une notification *"S√©lectionner l'interpr√©teur Python"*, choisis l‚Äôinterpr√©teur correspondant √† ton environnement `.venv`.

### 4. Cr√©er un dossier pour ton notebook

Organise tes fichiers en cr√©ant un dossier d√©di√© √† l‚Äôanalyse :

```bash
mkdir dataanalysis
touch dataanalysis/movie_data_analysis.ipynb
```

### 5. Installer le SDK `moviesdk`

Ce SDK te permettra d‚Äôinteragir avec l‚ÄôAPI MovieLens. Installe-le dans ton environnement :

```bash
pip install moviesdk
```

### 6. Lancer et configurer le Jupyter Notebook

Ouvre ton fichier `.ipynb` dans VSCode. Lorsque tu ex√©cutes ta **premi√®re cellule**, si Jupyter n‚Äôest pas encore install√©, VSCode te proposera automatiquement de l‚Äôinstaller (avec `ipykernel`). Accepte pour que tout soit configur√© automatiquement.

---

**Ton environnement est pr√™t !**

Tu peux maintenant d√©marrer ton **analyse exploratoire interactive** directement dans le fichier `movie_data_analysis.ipynb`.  
On va explorer les films, les notes, les genres... et visualiser tout √ßa avec des graphiques dynamiques !























































Suite du Projet movielens-project

##  Data Analysis sur Notebook jupyter

- Le Data Analyst va se familiariser avec l'API via le SDK 

- Comprendre l'ensemble des donn√©es

- V√©rifier le format des colonnes pour les r√©sultats en pandas dataframe

- Calcul de Sparsity = Number of Ratings in Matrix / (Number of Users * Number of Movies). Il s'agie de la parcimonie. Elle mesure le degr√© de vide d'une matrice, ou du pourcentage de la matrice qui est vide. En substance, cette formule est simplement le nombre de notes qu'une matrice contient divis√© par le nombre de notes qu'elle pourrait contenir √©tant donn√© le nombre d'utilisateurs et de films dans la matrice.

***Remember that sparsity is calculated by the number of cells in a matrix that contain a rating divided by the total number of values that matrix could hold given the number of users and items (movies). In other words, dividing the number of ratings present in the matrix by the product of users and movies in the matrix and subtracting that from 1 will give us the sparsity or the percentage of the ratings matrix that is empty.***

Voici un exemple de calcul en PySPark. Tu dois √©crire la version Python √† l'aide du SDK.

Sparsity: numerator

```python
# Number of ratings in matrix (on compte le nombre de notes dans les notes)
numerator = ratings.count()
```

Sparsity: users and movies

```python
# Distinct users and movies (Nombre d'utilisateurs distincs et le nombre d'√©l√©ments ou de films distincts)
users = ratings.select("userId").distinct().count() # La m√©thode .distinct() renvoie simplement toutes les valeurs uniques d'une colonne.
movies = ratings.select("movieId").distinct().count()
```

Sparsity: denominator

```python
# Number of ratings matrix could contain if no empty cells (Multiplication du nombre d'utilisateurs et de nombre de films pour obtenir le d√©nominateur)
denominator = users * movies
```

Sparsity

```python
#Calculating sparsity (Diviser simplement le num√©rateur par le d√©nominateur et soustrayer le r√©sultat de 1)
sparsity = 1 - (numerator*1.0 / denominator)
print ("Sparsity: "), sparsity
print("The ratings dataframe is ", "%.2f" % sparsity + "% empty.")
```

- general summary metrics of the ratings dataset and see how many ratings the movies have and how many ratings each users has provided.

Exemple de code en PySpark. Tu dois √©crire la version correspondante en Python √† l'aide du SDK

```python
# Import the requisite packages
from pyspark.sql.functions import col

# View the ratings dataset
ratings.show()

# Filter to show only userIds less than 100
ratings.filter(col("userId") < 100).show()

# Group data by userId, count ratings
ratings.groupBy("userId").count().show()
```

- MovieLens Summary Statistics

Exemple de code en PySpark. Tu dois √©crire la version correspondante en Python √† l'aide du SDK

```python
# Min num ratings for movies
from pyspark.sql.functions import min, avg

print("Movie with the fewest ratings: ")
ratings.groupBy("movieId").count().select(min("count")).show()

# Avg num ratings per movie
print("Avg num ratings per movie: ")
ratings.groupBy("movieId").count().select(avg("count")).show()

# Min num ratings for user
print("User with the fewest ratings: ")
ratings.groupBy("userId").count().select(min("count")).show()

# Avg num ratings per user
print("Avg num ratings per user: ")
ratings.groupBy("userId").count().select(avg("count")).show()
```

***Exemple de commentaire √† faire :  Users have at least 20 ratings and on average of 149 ratings. And movies have at least 1 rating with an average of 11 ratings.***